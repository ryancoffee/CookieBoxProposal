We will likely use mutliple, computationally expensive, pulse retrieval algorithms \cite{Thomas2015,HJWorner2018} to determine the ``ground truth'' for a sub-set of full fidelity recorded x-ray pulse shapes.

High speed FPGA-based algorithms so that data analysis can occur prior to transfer.
Only very small data must be transferred over the network to remote data recording nodes.
Furthermore, the tight causal connection between electron bunch and x-ray pulse motivates a direct measurement of the shot-to-shot timing in correlation with high-rate electron bunch diagnostics. 


Data handling is a key challenge for which we plan to use a FPGA-based machine learning inferencing.
The inference model will be trained based on a transfer learning paradigm whereby the central hidden layers, e.g. the simulation trained core layers, will be optimized to recover x-ray pulse shapes (ground truth) given simulated angular streaking results.
The next step of the model training then adds a thin surface set of layers at the input side that is connected to the raw data of the detector.
Also, we will connect via a similarly thin set of layers that connect the preliminary output to the now data-based pulse reconstructions.
We expect that such an architecture will preserve the physics of angular streaking as contained in the simulations, while also incorporating the raw sensor calibrations as well as adjusting to any remaining systematic errors in the retrieval interpretation.

The on-board analysis of the data is a challenging bottleneck in the angular streaking scheme.
The raw data in angular streaking is the digitized waveform spanning about 200 ns of record length with a sample frequency of ideally about 4GS/s, one waveform for each of the 16 detectors.
All together this would be comparable to a 12.8 kPix image being fed into the analysis layer.
We estimate a maximum duty-cycle above 100 kHz by comparing to the 1\% CMOS ROI discusses in Objective~\ref{obj::controlling}, assuming that the analysis algorithm can keep up with the data frame rate.
%Detailed in the forthcoming Ref.~\cite{Nick2016}, we iteratively account for intensity in the polar representation of the angular photo-electron spectrum.
%This so called ``PacMan'' routine is iterative and therefore computationally intensive.
Instead of our original iterative retrieval algorithm \cite{Nick2016}, we plan here to develop a mapping technique that could be implemented as a simple on-board matrix multiplication.
In parallel to our pursuit of a mapping algorithm, we will continue our pursuit of machine learning to predict the multi-pulse delays and multi-color separations based only on electron beam information.
Through the active collaboration with the Marangos group we have focused initially on using the small data from electron bunch diagnostics as inputs to various machine learning algorithms. \cite{AlvaroML2016}
The various models are trained based on measured spectra of the final x-ray pulses and the temporal profiles based on XTCAV measurements.
After training, the electron bunch diagnostics are used to predict x-ray pulse characteristics such as inter-pulse delay and double pulse separation with 95\% or better predictive accuracy (Fig.~\ref{AlvaroIdea}) Ref.~\cite{AlvaroML2016}. 

\begin{wrapfigure}[27]{r}{.5\linewidth}
\vspace{-1\baselineskip}
\centerline{
%\includegraphics[trim={0 5cm 0 0},height=4cm]{face_106.crop.connectedlayers.eps}
%\includegraphics[width=\linewidth]{AlvaroArXive1610.03378v1_corrs.eps}
%\vrule
}
\hrule
\centerline{
%\includegraphics[trim={5.6cm -1cm 0 0},clip,width=\linewidth]{AlvaroArXive1610.03378v1_energies.eps}
}
\vspace{-2\baselineskip}
\caption{\label{AlvaroIdea} The efficacy of machine learning for predicting temporal delay (top) and color separation (bottom) for shaped FEL pulses. \cite{AlvaroML2016}}
\end{wrapfigure}

Through another collaboration with the data analysis group at LCLS we are exploring the use of convolutional neural networks for so-called ``deep learning.'' % for image interpretation.
Convolutional neural networks (CNNs) represent the most widely used machine learning architecture for image classification that can also be implemented directly into on-board analysis hardware \cite{cognimem}.
We are seeking deep learning methods such as ``guided'' and ``relevance'' back propagation to uncover the physical basis of how a neural network determines its predictive outputs \cite{Mihir}.
Whether it is a physics based algorithm, a physically interpretable neural network, or simply black-box machine learning, we expect an on-board analysis architecture that will significantly reduce the required data transfer and ideally produce x-ray pulse time-domain waveforms with a duty cycle above 10 kHz.


