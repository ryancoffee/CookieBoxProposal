We will in parallel develop a pulse retrieval pipeline that will reconstruct two-color x-ray pulses.

Data handling is a key challenge for which we plan to use a FPGA-based machine learning inferencing.
The inference model will be trained based on a transfer learning paradigm whereby the central hidden layers, e.g. the simulation trained core layers, will be optimized to recover x-ray pulse shapes (ground truth) given simulated angular streaking results.
The next step of the model training then adds a thin surface set of layers at the input side that is connected to the raw data of the detector.
Also, we will connect via a similarly thin set of layers that connect the preliminary output to the now data-based pulse reconstructions.
We expect that such an architecture will preserve the physics of angular streaking as contained in the simulations, while also incorporating the raw sensor calibrations as well as adjusting to any remaining systematic errors in the retrieval interpretation.

The on-board analysis of the data is a challenging bottleneck in the angular streaking scheme.
The raw data in angular streaking is the digitized waveform spanning about 200 ns of record length with a sample frequency of ideally about 4GS/s, one waveform for each of the 16 detectors.
All together this would be comparable to a 12.8 kPix image being fed into the analysis layer.
We estimate a maximum duty-cycle above 100 kHz by comparing to the 1\% CMOS ROI discusses in Objective~\ref{obj::controlling}, assuming that the analysis algorithm can keep up with the data frame rate.
Detailed in Ref.~\cite{Nick2018}, we iteratively account for intensity in the polar representation of the angular photo-electron spectrum.
This so called ``PacMan'' routine as well as a similar method of projections \cite{Siqi2018} are computationally expensive.
We therefore plan to reserve these and other retrieval methods \cite{Thomas2015,HJWorner2018} for the generation of so-called ``ground truth'' for a sub-set of full fidelity recorded x-ray pulse shapes.
This sub-set wil lthen be used for training and validating a faster inference matrix solution that could be implemented as a series of FPGA-based on-board matrix multiplications.
Only very small data of the retrieved pulse would be transferred over the network to remote data recording nodes along with intermittent high fidelity shots for the validation and re-training when needed.
We will use simulations of angular streaking from expected FEL pulses, together with the detector array simulations used for the design modelling, to iterate on the detector hardware configurations and the analysis pipeline from electronics to inference output.

HERE HERE HERE 




Through the active collaboration with the Marangos group we have focused initially on using the small data from electron bunch diagnostics as inputs to various machine learning algorithms. \cite{AlvaroML2016}
The various models are trained based on measured spectra of the final x-ray pulses and the temporal profiles based on XTCAV measurements.
After training, the electron bunch diagnostics are used to predict x-ray pulse characteristics such as inter-pulse delay and double pulse separation with 95\% or better predictive accuracy (Fig.~\ref{AlvaroIdea}) Ref.~\cite{AlvaroML2016}. 

\begin{wrapfigure}[27]{r}{.5\linewidth}
\vspace{-1\baselineskip}
\centerline{
%\includegraphics[trim={0 5cm 0 0},height=4cm]{face_106.crop.connectedlayers.eps}
%\includegraphics[width=\linewidth]{AlvaroArXive1610.03378v1_corrs.eps}
%\vrule
}
\hrule
\centerline{
%\includegraphics[trim={5.6cm -1cm 0 0},clip,width=\linewidth]{AlvaroArXive1610.03378v1_energies.eps}
}
\vspace{-2\baselineskip}
\caption{\label{AlvaroIdea} The efficacy of machine learning for predicting temporal delay (top) and color separation (bottom) for shaped FEL pulses. \cite{AlvaroML2016}}
\end{wrapfigure}

Through another collaboration with the data analysis group at LCLS we are exploring the use of convolutional neural networks for so-called ``deep learning.'' % for image interpretation.
Convolutional neural networks (CNNs) represent the most widely used machine learning architecture for image classification that can also be implemented directly into on-board analysis hardware \cite{cognimem}.
We are seeking deep learning methods such as ``guided'' and ``relevance'' back propagation to uncover the physical basis of how a neural network determines its predictive outputs \cite{Mihir}.
Whether it is a physics based algorithm, a physically interpretable neural network, or simply black-box machine learning, we expect an on-board analysis architecture that will significantly reduce the required data transfer and ideally produce x-ray pulse time-domain waveforms with a duty cycle above 10 kHz.


